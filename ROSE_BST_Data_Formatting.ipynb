{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('enriched_BST_data_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split different parts of the report into separate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reports(df, text_data):\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        reports = re.split(r\"\\s+\\d+\\.\\s+\", row[text_data])\n",
    "\n",
    "        reports = [report for report in reports if report.strip()]\n",
    "\n",
    "        reports_df = pd.DataFrame({text_data: reports})\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col != text_data:\n",
    "                reports_df[col] = row[col]\n",
    "\n",
    "        new_df = new_df.append(reports_df, ignore_index=True)\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = split_reports(df, 'text_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='text_data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Method (Touch Prep vs FNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_method(row, text_column):\n",
    "    if re.search(r'touch prep', row[text_column], flags=re.IGNORECASE):\n",
    "        return \"Touch Prep\"\n",
    "    elif re.search(r'aspirate|aspiration', row[text_column], flags=re.IGNORECASE):\n",
    "        return \"FNA\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Method'] = df.apply(lambda row: determine_method(row, 'part_description'), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Adequacy Statement and SIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_adequacy_statement(row, text_data):\n",
    "#     match = re.search(r'Statement of Adequacy:(.*?\\.)', row[text_data], flags=re.IGNORECASE)\n",
    "#     if match:\n",
    "#         return ''.join(match.groups(default='')).strip()\n",
    "#     else:\n",
    "#         return None\n",
    "    \n",
    "# #def extract_sind_statement(row, text_data):\n",
    "#     match = re.search(r'(Although .*?\\.)', row[text_data], flags=re.IGNORECASE)\n",
    "#     if match:\n",
    "#         return ''.join(match.groups(default='')).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adequacy_statement(row, text_data):\n",
    "    match = re.search(r'(Although .*?\\.)', row[text_data], flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        return ''.join(match.groups(default='')).strip()\n",
    "    \n",
    "    match = re.search(r'Statement of Adequacy:(.*?\\.)', row[text_data], flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        return ''.join(match.groups(default='')).strip()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AdequacyStatement'] = df.apply(lambda row: extract_adequacy_statement(row, 'text_data'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df['AdequacyStatement'] = new_df.apply(lambda row: extract_adequacy_statement(row, 'text_data'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df['AdequacyStatement'] = new_df.apply(lambda row: extract_sind_statement(row, 'text_data'), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Number of Passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_attempts(row, text_column):\n",
    "    match = re.search(r'Immediate adequacy assessment(.*)', row[text_column])\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "\n",
    "        adequate_count = len(re.findall(r'\\bAdequate\\b', text))\n",
    "        not_adequate_count = len(re.findall(r'\\bNot Adequate\\b', text))\n",
    "        inadequate_count = len(re.findall(r'\\bInadequate\\b', text)) + not_adequate_count\n",
    "\n",
    "        continue_after_adequate = 'Adequate' in text and ('Inadequate' in text[text.index('Adequate'):] or 'Not Adequate' in text[text.index('Adequate'):])\n",
    "\n",
    "        return pd.Series([adequate_count, inadequate_count, continue_after_adequate])\n",
    "    else:\n",
    "        return pd.Series([0, 0, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['AdequateCount', 'InadequateCount', 'ContinueAfterAdequate']] = df.apply(lambda row: count_attempts(row, 'text_data'), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Final Diagnosis Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diagnosis(text):\n",
    "    match = re.search(r'(?i)(Positive for malignant cells|Negative for malignant cells)[\\.,](.*?)(\\.|$)', text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1) + match.group(2) + '.'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diagnosis(text):\n",
    "    pattern_label_mapping = {\n",
    "        'Positive for malignant cells': 'Positive for malignant cells',\n",
    "        'Negative for malignant cells': 'Negative for malignant cells',\n",
    "        'Malignant cells detected': 'Positive for malignant cells',\n",
    "        'No malignant cells detected': 'Negative for malignant cells',\n",
    "        'No malignant cells identified': 'Negative for malignant cells',\n",
    "        'No malignant cells seen': 'Negative for malignant cells',\n",
    "        'neoplastic cells present': 'Positive for neoplastic cells',\n",
    "        'plasma cell neoplasm': 'Positive for neoplastic cells',\n",
    "        'suspect adenocarcinoma': 'Suspicious for carcinoma',\n",
    "        'suspect carcinoma': 'Suspicious for carcinoma',\n",
    "        'suspicious for carcinoma': 'Suspicious for carcinoma',\n",
    "        'suspect lymphoma': 'Suspicious for lymphoma',\n",
    "        'suspicious for lymphoma': 'Suspicious for lymphoma',\n",
    "        'rare spindle cells present': 'Suspicious for sarcoma',\n",
    "        'suspect sarcoma': 'Suspicious for sarcoma',\n",
    "        'suspicect chondrosarcoma': 'Suspicious for sarcoma',\n",
    "        'spindle cell proliferation': 'Suspicious for sarcoma',\n",
    "        'suspicious cells present': 'Suspicious cells present',\n",
    "        'atypical cells': 'Atypical',\n",
    "        'atypical.': 'Atypical',\n",
    "        'atypical spindle cells': 'Atypical',\n",
    "        'atypical epithelial' : 'Atypical',\n",
    "    }\n",
    "    \n",
    "    for pattern, label in pattern_label_mapping.items():\n",
    "        if re.search(rf'(?i)({pattern})', text, flags=re.DOTALL | re.IGNORECASE):\n",
    "            return label\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cyto_diagnosis'] = df['cyto_report'].apply(find_diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('enriched_BST_data_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Concurrent Case Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_pattern = r'(?i)concurrent.*?([HS]\\d{2}-\\d+)'\n",
    "#flow_pattern = r'([F]\\d{2}-\\d+)'\n",
    "df['concurrent'] = df['text_data'].str.extract(concurrent_pattern)\n",
    "#lym_df['FLOW'] = lym_df['text_data_final'].str.extract(flow_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BST_WIP.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c835960ce2a382a4a46b664547a954b5a34b705ee9bb2cd6a22b95841cac96b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
